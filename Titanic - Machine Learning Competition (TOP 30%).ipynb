{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "3f9adafc-2291-45bb-b320-92821840cfc3",
        "_uuid": "2bfab440b45c7b1cbeed2b7e517330c7e3ef9081"
      },
      "cell_type": "markdown",
      "source": "# Titanic  - Random Forest Classifier\nSince I've done the Titanic exercise about a thousand times, I decided to go straight to the data manipulation and creating the model, since I already have a good understanding of how to features correlate.\n\nThere is stil a lot of room for improvement (obviously) regarding feature engineering, but I'm pretty happy with what I achieved so far. Specially considering this is my first kernel on Kaggle."
    },
    {
      "metadata": {
        "_cell_guid": "c312fb9b-fd20-4975-ab0b-cd11395e73fd",
        "_uuid": "2d31ebbff37f1b1cfdb43a3ebc2bc8a6af17adf1",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Imports\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set_style('darkgrid')",
      "execution_count": 44,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b43157a5-f827-4509-a808-58ebb821f017",
        "_uuid": "ba5404c0398e00cbd672c311f2d7b089ac465dd6",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Importing the data and checking the first 5 lines of it.\n\ntitanic_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')\ntitanic_df.head()",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ",
            "text/html": "<div>\n<style>\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "execution_count": 45,
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "069d4c26-6da4-4c36-8344-6a81d38ecb6a",
        "_uuid": "4ca025f8ef1e8dc166ef85f655dcaabaec69960c",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Now let's check the info on both titanic_df and test_df\n\nprint(titanic_df.info())\nprint('---------------------------------------')\nprint(test_df.info())",
      "execution_count": 46,
      "outputs": [
        {
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\nPassengerId    891 non-null int64\nSurvived       891 non-null int64\nPclass         891 non-null int64\nName           891 non-null object\nSex            891 non-null object\nAge            714 non-null float64\nSibSp          891 non-null int64\nParch          891 non-null int64\nTicket         891 non-null object\nFare           891 non-null float64\nCabin          204 non-null object\nEmbarked       889 non-null object\ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.6+ KB\nNone\n---------------------------------------\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 418 entries, 0 to 417\nData columns (total 11 columns):\nPassengerId    418 non-null int64\nPclass         418 non-null int64\nName           418 non-null object\nSex            418 non-null object\nAge            332 non-null float64\nSibSp          418 non-null int64\nParch          418 non-null int64\nTicket         418 non-null object\nFare           417 non-null float64\nCabin          91 non-null object\nEmbarked       418 non-null object\ndtypes: float64(2), int64(4), object(5)\nmemory usage: 36.0+ KB\nNone\n",
          "name": "stdout",
          "output_type": "stream"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "a599b8f4-c0c8-4961-a163-a592b4724bbc",
        "_uuid": "81e71e7210f27d66944323c923aca6d1503bb063",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Checking for missing values on both data sets\n\nprint(titanic_df.isnull().sum())\nprint('------------------')\nprint(test_df.isnull().sum())",
      "execution_count": 47,
      "outputs": [
        {
          "text": "PassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n------------------\nPassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n",
          "name": "stdout",
          "output_type": "stream"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "f1f17dcd-143a-4fd9-946d-2a488d63babf",
        "_uuid": "86ef74b3ea05eeb62a707de4b6acbe54c3a7f72e",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Let's check the most common value in 'Embarked', so we can fill the 2 Nan's in titanic_df\n\ntitanic_df['Embarked'].value_counts()",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "S    644\nC    168\nQ     77\nName: Embarked, dtype: int64"
          },
          "execution_count": 48,
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "59579597-d3ad-4bd8-99e0-8f5942dd201a",
        "_uuid": "2f6a49ab8ca2a8784eb49028cfe37c68d7fef87e",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "titanic_df['Embarked'].fillna('S', inplace=True)\ntest_df['Fare'].fillna(test_df['Fare'].mean(), inplace=True)",
      "execution_count": 49,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0cb329a2-e99b-43e2-a116-6ca48eecd59b",
        "_uuid": "74fd7a684308db430b202658d354c06213b3cb94",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Here I'm trying to find what's the average age by class, so we can more accurately fill the\n# missing values in the 'Age' column\n\nfirst_class_age = int(titanic_df[titanic_df['Pclass'] == 1]['Age'].mean())\nsecond_class_age = int(titanic_df[titanic_df['Pclass'] == 2]['Age'].mean())\nthird_class_age = int(titanic_df[titanic_df['Pclass'] == 3]['Age'].mean())",
      "execution_count": 50,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b1dd8804-6af7-424e-9289-488a7af676d4",
        "_uuid": "a1867dcd89aaf98174e744edac6cc0cb415fb3a1",
        "trusted": false
      },
      "cell_type": "code",
      "source": "print('First Class Average Age: {}'.format(first_class_age))\nprint('Second Class Average Age: {}'.format(second_class_age))\nprint('Third Class Average Age: {}'.format(third_class_age))",
      "execution_count": 51,
      "outputs": [
        {
          "text": "First Class Average Age: 38\nSecond Class Average Age: 29\nThird Class Average Age: 25\n",
          "name": "stdout",
          "output_type": "stream"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "66cd1819-3dcb-4a5b-a621-3feeba7e09d6",
        "_uuid": "fc263fe01ef59801ec71489ea95e14f72f72675e",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Now that we have the average age by class, let's fill those NaN's\n\ndef empute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        if Pclass == 1:\n            return first_class_age\n        elif Pclass == 2:\n            return second_class_age\n        else:\n            return third_class_age\n    else:\n        return Age",
      "execution_count": 52,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "522fc1bf-2345-46ce-bfd9-cafc2e26bd2e",
        "_uuid": "1d4f488d3e55c4cc4960ace6b036c26e6a42d14a",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "titanic_df['Age'] = titanic_df[['Age', 'Pclass']].apply(empute_age, axis=1)\ntest_df['Age'] = test_df[['Age', 'Pclass']].apply(empute_age, axis=1)",
      "execution_count": 53,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "592aa36e-31f1-481c-8d7b-3ef8df6553ee",
        "_uuid": "93723198ebd941d7fe43340a999510315071c4ab",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# We can drop the Cabin column since it's missing so many values, and I don't think we can\n# feature engineering it.\n\ntitanic_df.drop('Cabin', axis=1, inplace=True)\ntest_df.drop('Cabin', axis=1, inplace=True)",
      "execution_count": 54,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "aa06bbbe-7540-4163-bf88-0d1a7e3607f3",
        "_uuid": "02ce209fb0e7cee1f73e50e63c962dd8aa7133df",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Let's get the lenght of names into a new column, since that has a relationship with survival\n# rate\n\ntitanic_df['Name_Len'] = titanic_df['Name'].apply(lambda x: len(x))\ntest_df['Name_Len'] = test_df['Name'].apply(lambda x: len(x))",
      "execution_count": 55,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "fd7efbf5-018f-4539-b6e1-8ac5d54fab78",
        "_uuid": "0fac686254fd3d382af861d1f64a247c4fb48152",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# We can also take the title out of the 'Name' feature and put it in a new column\n\ntitanic_df['Name_Title'] = titanic_df['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0])\ntest_df['Name_Title'] = test_df['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0])",
      "execution_count": 56,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "8991d388-b5aa-436a-9913-2b6dc183af0d",
        "_uuid": "815a2eb00c40f44371cb2152e6ec21910c554a07",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Let's check the titles\n\nprint(titanic_df['Name_Title'].value_counts())\nprint('--------------------')\nprint(test_df['Name_Title'].value_counts())",
      "execution_count": 57,
      "outputs": [
        {
          "text": "Mr.          517\nMiss.        182\nMrs.         125\nMaster.       40\nDr.            7\nRev.           6\nMlle.          2\nMajor.         2\nCol.           2\nDon.           1\nSir.           1\nCapt.          1\nthe            1\nJonkheer.      1\nMme.           1\nLady.          1\nMs.            1\nName: Name_Title, dtype: int64\n--------------------\nMr.        240\nMiss.       78\nMrs.        72\nMaster.     21\nRev.         2\nCol.         2\nDr.          1\nMs.          1\nDona.        1\nName: Name_Title, dtype: int64\n",
          "name": "stdout",
          "output_type": "stream"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "c7d05b3c-30ea-4cf8-854d-2b588aff367e",
        "_uuid": "1aad928f613b4326d55af9bb614bce5805e3f157",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# We can create a dictionary for the titles with values to be used as dummy variables in our\n# model\n\ntitles = {'Mr.': 0, 'Miss.': 1, 'Mrs.': 2, 'Master.': 3, 'Dr.': 4, 'Rev.': 5, 'Major.': 6,\n          'Col.': 7, 'Mlle.': 8, 'Jonkheer.': 9, 'Sir.': 10, 'Mme.': 11, 'the': 12, 'Don.': 13,\n          'Capt.' : 14, 'Lady.': 15, 'Ms.': 16, 'Dona.': 17\n         }",
      "execution_count": 58,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1b04d474-dfc4-4162-9654-b44ae2600ce0",
        "_uuid": "d1e76417fe2769ccb4787f7211dd4b36001fcd74",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Replacing the titles for their correspondent dummy variable\n\ntitanic_df['Name_Title'].replace(titles, inplace=True)\ntest_df['Name_Title'].replace(titles, inplace=True)",
      "execution_count": 59,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "5b7a9e31-cdb3-484c-988d-ec5094ea635a",
        "_uuid": "1b872683386e72f057509030062d385121a853d4",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Getting dummy variables\n\nsex_dummy_titanic = pd.get_dummies(titanic_df['Sex'], drop_first=True)\nsex_dummy_test = pd.get_dummies(test_df['Sex'], drop_first=True)\n\nembark_dummy_titanic = pd.get_dummies(titanic_df['Embarked'], drop_first=True)\nembark_dummy_test = pd.get_dummies(test_df['Embarked'], drop_first=True)",
      "execution_count": 60,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "07736a6c-f0d9-41cd-9974-e2edbb0a69f3",
        "_uuid": "e368e4e7129d9ad8ed59c9e74d0489d48f00b4aa",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Let's drop the rest of the columns that we are not going to use\n# Note that we are not dropping the PassengerId in the test_df because we need it for our\n# submission file for the competition\n\ntitanic_df.drop(['PassengerId', 'Name', 'Sex', 'Ticket', 'Embarked'], axis=1, inplace=True)\ntest_df.drop(['Name', 'Sex', 'Ticket', 'Embarked'], axis=1, inplace=True)",
      "execution_count": 61,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "bc8808e5-d577-4d6d-8556-29d80f645c01",
        "_uuid": "b21b24bafe6278dd2007b67dedcf083d6718bf84",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# It's time to start modeling, first let's separate training and testing sets\n\nfrom sklearn.model_selection import train_test_split",
      "execution_count": 62,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "15e2c2ca-2f07-4e67-8169-21d93427fabc",
        "_uuid": "998d11ce80428e91094f28592b3cb688bdfd67c3",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# We will use only the data from titanic_df because we want to get accuracy_score, after we\n# selected the best model, we'll use it to predict on the test_df\n\nX = titanic_df.drop('Survived', axis=1)\ny = titanic_df['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101)",
      "execution_count": 63,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b33f0e20-77e8-48b8-b638-6cd8777f178d",
        "_uuid": "275c2924668c02c1a977a10977759c92ebb7d59f",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Importing evaluation modules\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.grid_search import GridSearchCV",
      "execution_count": 64,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "99c9a9b8-78df-41c2-aba1-71bdeb1b6b4e",
        "_uuid": "0779d5357261541af07187d6977a1835c296fe6d",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Decision Tree \n\nfrom sklearn.tree import DecisionTreeClassifier",
      "execution_count": 65,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "4a4d4231-8854-4a72-a83f-a148d9a04664",
        "_uuid": "c9d4394249b14470bde993c9b9e58294597cb9c4",
        "trusted": false
      },
      "cell_type": "code",
      "source": "dt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)\ndt_pred = dt.predict(X_test)\ndt_acc = accuracy_score(y_test, dt_pred)\nprint('Accuracy: {}'.format(dt_acc))",
      "execution_count": 66,
      "outputs": [
        {
          "text": "Accuracy: 0.7593220338983051\n",
          "name": "stdout",
          "output_type": "stream"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "c12d7645-f52c-444c-bf49-c8e25f95c5a8",
        "_uuid": "b05060cd9e8857d14e1474b1021d46868ace101b",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Random Forest Classifier\n\nfrom sklearn.ensemble import RandomForestClassifier",
      "execution_count": 67,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "89d65cb4-300f-46c7-979b-a4f2ae0d25e0",
        "_uuid": "3163a178e87979e57ada028769911224b12eaebe",
        "trusted": false
      },
      "cell_type": "code",
      "source": "score = []\n\nfor i in range(1, 101):\n    clf = RandomForestClassifier(n_estimators=i, criterion='entropy', random_state=101)\n    clf.fit(X_train, y_train)\n    clf_pred = clf.predict(X_test)\n    score.append(accuracy_score(y_test, clf_pred))\n    \nprint(max(score))",
      "execution_count": 68,
      "outputs": [
        {
          "text": "0.840677966102\n",
          "name": "stdout",
          "output_type": "stream"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "035d77aa-e18c-434a-9d74-7110813ab751",
        "_uuid": "cac9cb95d5bd05ade0c193338dd33132eec28b21",
        "trusted": false
      },
      "cell_type": "code",
      "source": "score.index(max(score))",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "18"
          },
          "execution_count": 69,
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "73e24575-4ea5-419f-8bb0-5bc7c3d5fd8a",
        "_uuid": "4167b87c5b5eb30e45b7b8dcb9914dddf267f7de",
        "trusted": false
      },
      "cell_type": "code",
      "source": "params = {\n    'n_estimators': list(range(1, 101)),\n    'criterion': ['entropy'],\n    'random_state': [101]\n}\n\ngrid = GridSearchCV(RandomForestClassifier(), param_grid=params)\ngrid.fit(X_train, y_train)\nprint('Best estimator: {}'.format(grid.best_estimator_))\nprint('Best parameters: {}'.format(grid.best_params_))\nprint('Best score: {}'.format(grid.best_score_))",
      "execution_count": 70,
      "outputs": [
        {
          "text": "Best estimator: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=84, n_jobs=1,\n            oob_score=False, random_state=101, verbose=0, warm_start=False)\nBest parameters: {'criterion': 'entropy', 'n_estimators': 84, 'random_state': 101}\nBest score: 0.7869127516778524\n",
          "name": "stdout",
          "output_type": "stream"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "30aa1bc6-ad7b-46d5-8631-a00db9b53e1b",
        "_uuid": "ae16c3b0ce0c9bdc4c4ea329d89f15163d30ce30",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Funny how the GridSearch gives me a different n_estimator then my for loop. And my for\n# loop result is much better then the GridSearch. Maybe I'm missing something here idk?",
      "execution_count": 71,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "8b9fe061-ca5f-4fe6-b2df-1e6cfa23a0a0",
        "_uuid": "db9bf8dbad8b8e8f35d7f046dd2ec0d302c5799a",
        "trusted": false
      },
      "cell_type": "code",
      "source": "random_forest = RandomForestClassifier(n_estimators=19, criterion='entropy', random_state=101)\nrandom_forest.fit(X_train, y_train)\nrfc_pred = random_forest.predict(X_test)\nrfc_acc = accuracy_score(y_test, rfc_pred)\nprint('Accuracy: {}'.format(rfc_acc))",
      "execution_count": 72,
      "outputs": [
        {
          "text": "Accuracy: 0.8406779661016949\n",
          "name": "stdout",
          "output_type": "stream"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "cca5657a-fd2e-439a-95ac-71b0862cf742",
        "_uuid": "d99da10a9cbac30c06fa58b821b1d181d61b7083",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Logistic Regression\n\nfrom sklearn.linear_model import LogisticRegression",
      "execution_count": 73,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f159f736-3747-4548-b462-8bbc4d097117",
        "_uuid": "f2d459c7c75cda44fa288695266d6c46965da295",
        "trusted": false
      },
      "cell_type": "code",
      "source": "params_logreg = {\n    'C': [0.1, 1, 10, 100]\n}\n\ngrid_logistic = GridSearchCV(LogisticRegression(), param_grid=params_logreg)\ngrid_logistic.fit(X_train, y_train)\nprint('Best estimator: {}'.format(grid_logistic.best_estimator_))\nprint('Best parameters: {}'.format(grid_logistic.best_params_))\nprint('Best score: {}'.format(grid_logistic.best_score_))",
      "execution_count": 74,
      "outputs": [
        {
          "text": "Best estimator: LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)\nBest parameters: {'C': 0.1}\nBest score: 0.7802013422818792\n",
          "name": "stdout",
          "output_type": "stream"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "33a46be8-168f-445c-a8aa-5d2c8c5ba919",
        "_uuid": "e3a096bf79cf7e0c018eb16b40ae013d2159e6bc",
        "trusted": false
      },
      "cell_type": "code",
      "source": "logreg = LogisticRegression(C=0.1)\nlogreg.fit(X_train, y_train)\nlogreg_pred = logreg.predict(X_test)\nlogreg_acc = accuracy_score(y_test, logreg_pred)\nprint('Accuracy: {}'.format(logreg_acc))",
      "execution_count": 75,
      "outputs": [
        {
          "text": "Accuracy: 0.7322033898305085\n",
          "name": "stdout",
          "output_type": "stream"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "be2c3004-625c-4de4-b36b-2f931e42c1b6",
        "_uuid": "dd668494b8da4296666092840ea52164a723ec22",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Gaussian Naive Bayes\n\nfrom sklearn.naive_bayes import GaussianNB",
      "execution_count": 76,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "580d5a35-832a-432d-b1f0-a33de82f811f",
        "_uuid": "fd2afeb4df8c7b034b6e0ca942f869b86145a2fb",
        "trusted": false
      },
      "cell_type": "code",
      "source": "gnb = GaussianNB()\ngnb.fit(X_train, y_train)\ngnb_pred = gnb.predict(X_test)\ngnb_acc = accuracy_score(y_test, gnb_pred)\nprint('Accuracy: {}'.format(gnb_acc))",
      "execution_count": 77,
      "outputs": [
        {
          "text": "Accuracy: 0.6813559322033899\n",
          "name": "stdout",
          "output_type": "stream"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "ca1af5e7-33df-4a7a-aa0e-bba93c0ef2c4",
        "_uuid": "3079dd0250e97c24eb554bedf6fea23ff8ac3338",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# KNearest Neighbors\n\nfrom sklearn.neighbors import KNeighborsClassifier",
      "execution_count": 78,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0611433d-f7bb-41e2-8821-6b8ce2ef1049",
        "_uuid": "a9ebffa4a0cda0a8cce11723ea6f4d2d08388b78",
        "trusted": false
      },
      "cell_type": "code",
      "source": "params_knn = {\n    'n_neighbors': list(range(1, 41))\n}\n\ngrid_knn = GridSearchCV(KNeighborsClassifier(), param_grid=params_knn)\ngrid_knn.fit(X_train, y_train)\nprint('Best estimator: {}'.format(grid_knn.best_estimator_))\nprint('Best parameters: {}'.format(grid_knn.best_params_))\nprint('Best score: {}'.format(grid_knn.best_score_))",
      "execution_count": 79,
      "outputs": [
        {
          "text": "Best estimator: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=1, n_neighbors=6, p=2,\n           weights='uniform')\nBest parameters: {'n_neighbors': 6}\nBest score: 0.7332214765100671\n",
          "name": "stdout",
          "output_type": "stream"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "0c82fe99-032f-4eb7-b865-b8c0b2bf2118",
        "_uuid": "a5dfce8946bbfb109c382681eecbead40dd52f80",
        "trusted": false
      },
      "cell_type": "code",
      "source": "knn = KNeighborsClassifier(n_neighbors=6)\nknn.fit(X_train, y_train)\nknn_pred = knn.predict(X_test)\nknn_acc = accuracy_score(y_test, knn_pred)\nprint('Accuracy: {}'.format(knn_acc))",
      "execution_count": 80,
      "outputs": [
        {
          "text": "Accuracy: 0.7050847457627119\n",
          "name": "stdout",
          "output_type": "stream"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "eae7469a-ad37-42e3-b235-a4d2f9dad77a",
        "_uuid": "d56308ecc7f8e6942fac803985d1dd99bb1a8d1f",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# SGDClassifier\n\nfrom sklearn.linear_model import SGDClassifier",
      "execution_count": 81,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b66fdccf-0ac2-4500-8578-079d8620f868",
        "_uuid": "bc3f5584e460094a64cdf9679570d0e55dc48a09",
        "trusted": false
      },
      "cell_type": "code",
      "source": "params_sgdc = {\n    'alpha': [0.1, 0.01, 0.001, 0.0001]\n}\n\ngrid_sgdc = GridSearchCV(SGDClassifier(), param_grid=params_sgdc)\ngrid_sgdc.fit(X_train, y_train)\nprint('Best estimator: {}'.format(grid_sgdc.best_estimator_))\nprint('Best parameters: {}'.format(grid_sgdc.best_params_))\nprint('Best score: {}'.format(grid_sgdc.best_score_))",
      "execution_count": 82,
      "outputs": [
        {
          "text": "Best estimator: SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n       shuffle=True, tol=None, verbose=0, warm_start=False)\nBest parameters: {'alpha': 0.0001}\nBest score: 0.6728187919463087\n",
          "name": "stdout",
          "output_type": "stream"
        },
        {
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
          "name": "stderr",
          "output_type": "stream"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "f80e1a36-049c-4d20-a42e-ce215fee4450",
        "_uuid": "776ac4b57c81868286ba729749069f7dd5e626f0",
        "trusted": false
      },
      "cell_type": "code",
      "source": "sgdc = SGDClassifier(alpha=0.001)\nsgdc.fit(X_train, y_train)\nsgdc_pred = sgdc.predict(X_test)\nsgdc_acc = accuracy_score(y_test, sgdc_pred)\nprint('Accuracy: {}'.format(sgdc_acc))",
      "execution_count": 83,
      "outputs": [
        {
          "text": "Accuracy: 0.7084745762711865\n",
          "name": "stdout",
          "output_type": "stream"
        },
        {
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
          "name": "stderr",
          "output_type": "stream"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "57babe7e-7dff-4821-9592-808e283dd400",
        "_uuid": "b32ea82554ce871b7bffaa89ec74b3bda09950b6",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Comparing accuracy from all the models\n\nlist_scores = [dt_acc, rfc_acc, logreg_acc, gnb_acc, knn_acc, sgdc_acc]\nclassifiers = ['Decision Tree', 'Random Forest', 'Logistic Regression', 'Gaussian Naive Bayes', 'KNN', 'SGDC']\n\nscores_df = pd.DataFrame(list_scores, columns=['Scores'], index=classifiers)\nscores_df",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "                        Scores\nDecision Tree         0.759322\nRandom Forest         0.840678\nLogistic Regression   0.732203\nGaussian Naive Bayes  0.681356\nKNN                   0.705085\nSGDC                  0.708475",
            "text/html": "<div>\n<style>\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Scores</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Decision Tree</th>\n      <td>0.759322</td>\n    </tr>\n    <tr>\n      <th>Random Forest</th>\n      <td>0.840678</td>\n    </tr>\n    <tr>\n      <th>Logistic Regression</th>\n      <td>0.732203</td>\n    </tr>\n    <tr>\n      <th>Gaussian Naive Bayes</th>\n      <td>0.681356</td>\n    </tr>\n    <tr>\n      <th>KNN</th>\n      <td>0.705085</td>\n    </tr>\n    <tr>\n      <th>SGDC</th>\n      <td>0.708475</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "execution_count": 84,
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "f319539a-046f-483b-ad96-fc14ce6c65d5",
        "_uuid": "27544cfc6384c68cfd2bfe9703d41e2a4009bfac",
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Now let's predict with random forest classifier on the test_df set\n\npredictions = random_forest.predict(test_df.drop('PassengerId', axis=1))",
      "execution_count": 85,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "50ca3475-0911-4294-aa89-44dbfeb36064",
        "_kg_hide-output": true,
        "collapsed": true,
        "_uuid": "cfc98e0da6611647eea7aced4c75667f0dcd190a",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Create a submission file to be sent to kaggle\n\nsubmission = pd.DataFrame(\n            {'PassengerId': test_df['PassengerId'],\n             'Survived': predictions})\nsubmission.to_csv('random_forest_classifier_3', index=False)",
      "execution_count": 86,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "354073b2-2813-453f-bbe1-d80cd64d4cf2",
        "_uuid": "fc2a22054fa0812ea827aa56d8804ea8b3d37fdd"
      },
      "cell_type": "markdown",
      "source": "I'm still trying to figure out how to properly tune the models with GridSearch. If you have any constructive critiscm, please go ahead! I'm looking forward to hearing your advices."
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
